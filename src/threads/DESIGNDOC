			+--------------------+
			|       EEL 770      |
			| PROJETO 1: THREADS |
			|      RELATÓRIO     |
			+--------------------+
				   
---- GRUPO ----

>> Fill in the names and email addresses of your group members.

Ary Andrade Neto <aryneto@poli.ufrj.br>
Lucas Santiago Peixoto <santiagolucas643@poli.ufrj.br>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

https://github.com/yuwumichcn223/pintos
https://github.com/microdog/pintos-project-1
https://github.com/Ma06RC/Pintos-Busy-Wait-

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

No arquivo timer.c:
	static struct list blocked_threads; ==> Lista para threads em espera bloqueadas.

No arquivo thread.h:
	int64_t sleep_ticks; ==> Tempo de alarme da thread.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Cada chamada ao timer_sleep() obtém o tempo atual do sistema em ticks que,
somados aos ticks que a thread em questão deve dormir, resultam no tempo
em ticks em que a thread acordará.

Após obter o ponteiro para a thread atual, a função timer_sleep() desabilita
interrupções, define o tempo do alarme na thread, insere a thread na lista
de threads bloqueadas, em ordem crescente em relação ao tempo do alarme
de cada thread, e por fim, bloqueia a thread com thread_block().

O handler timer_interrupt(), além de contar os ticks do sistema, acorda as
threads cujo tempo de alarme já passou. A cada chamada, ele tenta acordar a thread
na frente da lista, ou seja, com tempo de alarme menor. Se os ticks atuais forem maiores
que o tempo de alarme da thread, o handler retira a thread da lista, a desbloqueia
e tenta acordar a próxima.

Enquanto a thread na frente da lista tiver que acordar, e a lista de threads bloqueadas
não for vazia, o handler continua a despertar threads bloqueadas. Assim que uma não
tiver que acordar, ou seja, seu tempo não passou, as próximas também deverão continuar
dormindo, assim o handler termina sua execução. 


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

A inserção de threads dormindo na lista de threads bloqueadas em ordem crescente,
com relação ao tempo do alarme. Isso permite que o handler só procure as threads dormindo, e
acorde as primeiras threads, ou seja, as que estão mais próximas de acordar. Na primeira thread
que não for acordar, o handler termina sua execução.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Interrupções são desabilitadas antes da thread calcular seu tempo de alarme, podendo se inserir
na lista de espera bloqueada e se bloquear, permitindo outra thread entrar no seu lugar.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

O tempo de início, que é usado no cálculo do tempo de alarme,
é calculado assim que timer_sleep é chamado, impedindo que a
thread possa dormir mais que o esperado.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

Por indicação do professor e pela simplicidade de implementação.


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

No arquivo thread.h: 
	int base_priority; ==> Valor da prioridade básica da thread. Não é afetado pela doação prioritária.
	struct list locks; ==> Lista de locks adquiridos por uma thread.
	struct lock *blocked_on_lock; ==> O lock bloqueando atualmente a thread. Null se não houver.

No arquivo synch.h: 
	struct list_elem elem; ==> Objeto elemento de uma lista para adicionar à lista de locks do holder da thread.


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

	T1    T2  T3    T4
	^      ^  ^	 ^
	 \    /	   \    /
	  \  /	    \  /
	   vv	     vv
	   L1	     L2
	   ^	      ^
	   |	      |
	   v	      v
	   T5	     T6
	   ^	      ^
	    \	     /
	     \	    /
	      \	   /
	       \  /
		vv
		L3
		^
		|
		v
		T7
		 
T1 e T2 esperam por L1, segurado por T5.
T3 e T4 esperam por L2, segurado por T6.
T5 e T6 esperam por L3, segurado por T7.

Neste caso, T1 e T2 possuem L1 no campo de lock que elas esperam, com L1 tendo
essas threads na sua lista de espera. T5 tem L1 como o lock que ela segura, e L3
como o lock que ela espera. Essa organização bidirecional (pode-se encontrar T5
a partir de T1 e vice-versa) permite doação de prioridade aninhada, quando uma
thread que segura um lock estiver bloqueada por outro lock. A prioridade base é
usada para comparação entre as prioridades de outras threads, e a prioridade é
usada para ordenação na lista de threads em ready.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

A lista de threads em espera desses métodos de sincronização estão em
ordem descrescente de prioridade, ou seja, maior prioridade na frente.
No momento que uma thread cede espaço para outras executarem, as da frente
são removidas primeiro da lista de espera.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Assim que uma thread T1 chama lock_acquire em L1, assume-se que T1
ficará bloqueada, assim, seu blocked_by_lock é definido como L1.
Se uma thread T2 segurar L1 e a prioridade de T2 for menor que a de T1,
T1 doa sua prioridade para T2, insere-se T1 na lista de espera de L1,
mantendo a ordenação dessa lista, e bloquea-se T1, caso T2 não estiver
esperando por outro lock L2.

Se T2 estiver esperando por L2, definem-se dois ponteiros, um para a T2
e outro para L2, que permitem doação aninhada. Se T3, que segura L2, tiver
prioridade menor que T2, que agora possui a prioridade de T1, T2 doa sua
prioridade para T3. Os dois ponteiros passam para o próximo nível de thread-lock
caso T3 esteja esperando por um lock e se a prioridade de T2 era maior que a de
T3. Se não, a doação termina e o lock_acquire segue inserindo T1 na lista de espera
de L1 e bloqueando T1.

A cada doação, a o elemento de lista de thread que recebe a prioridade
é reposicionada na lista de acordo com a sua prioridade.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

Primeiro, removemos o lock L1 da lista de locks que a thread T1 segura. Depois,
redefine-se a prioridade de T1 usando sua prioridade base (que não conta doações)
e locks que T1 ainda possuir. Por fim, libera-se L1 para outra thread T2, com
a maior prioridade dentre as que esperam por L1, entrar.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Se uma thread T1 doar sua prioridade para uma thread T2 após definir o máximo,
tal máximo irá sobrescrever a doação de T1. Se a prioridade de T1 for a maior,
ela será sobrescrita. Esse erro é corrigido desabilitando interrupções.
O lock poderia ser usado, porém ele teria que ser incluído em todas as ocorrências
do thread_set_priority(). Como o lock muda a lista de locks que uma thread possui,
deadlocks podem ser gerados, pois o lock poderia se chamar em alguns casos.


---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

Manter a lista de espera de locks, semáforos e variáveis de condição ordenadas
pela prioridade permite remoção em O(1), embora a reordenação e inserção sejam O(n).
Escolher uma implementação iterativa por while, ao invés de uma puramente recursiva,
impede possível overflow na pilha de chamada de função.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

No arquivo thread.h:
	fixed_point recent_cpu; ==> Uso recente de cpu de thread.
	int nice; ==> Valor "nice" da thread.
	lib/kernel/FixedPoint.h ==> Aritmética de ponto fixo.

No arquivo thread.c:
	static struct thread * thread_min_mlfqs ==> A thread com menor uso de cpu recente;
	static fixed_point load_avg ==> O load average do escalonador 4.4BSD;
	static fixed_point load_coeff_1 ==> O coeficiente de load average no cálculo de load average;
	static fixed_point load_coeff_2 ==> O coeficiente de uso de cpu recente no cálculo de load average;


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

Tomando como slice de tempo = 4 ticks

timer  recent_cpu    priority   thread      ready
ticks   A   B   C   A   B   C   to run       list
-----  --  --  --  --  --  --   ------      ------
 0     0   0   0   63  61  59     A          B, C
 4     4   0   0   62  61  59     A          B, C
 8     8   0   0   61  61  59     A          B, C
12     12  0   0   60  61  59     B          A, C
16     12  4   0   60  60  59     B          A, C
20     12  8   0   60  59  59     A          C, B
24     16  8   0   59  59  59     A          C, B
28     20  8   0   58  59  59     C          B, A
32     20  8   4   58  59  58     B          A, C
36     20  12  4   58  58  58     A          C, B

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

Sim, pois a especificação do escalonador não explicita o caso de duas
threads com prioridades iguais. Nesse caso, usamos o Round Robin como
política de escalonamento, retirando a thread da execução caso sua
prioridade seja menor que a thread no topo da fila de threads em espera
de maior prioridade. Ao sair, tal thread entra no final da fila de sua prioridade.

Esse comportamento corresponde ao do escalonador, como visto na
função compare_thread_priority().

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Todo escalonamento é feito fora do contexto de interrupção, visando
melhor performance. Porém, tivemos que desabilitar interrupções na
maior parte dos escalonamentos para garantir a corretude dos valores,
e isso afeta a performance. Por isso, o ganho de performance comparado a
deixar tais escalonamentos dentro do contexto de interrupção é pequeno.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Vantagens:
    - Simples de implementar, tirando o FixedPoint.h
    - Uso eficiente de listas
    - Sincronização simples por desabilitar interrupções

Desvantagens:
    - Desabilitar interrupções afeta a performance do código
    - Por utilizar uma lista duplamente encadeada, operações
	como ordenação levam O(n^2) ao invés de O(n*log(n))

Possíveis melhorias:
    - Implementação de outras estruturas de dados para acelerar
	execução de códigos em listas (hashtable/árvore binária)
    - Utilização de locks/semáforos/variáveis de condição para
	acabar com concorrência entre threads.

Curiosidades:
    - Deixar a thread executando até que sua prioridade seja menor
	que outra thread permite que esta thread fique mais tempo,
	porém desencoraja maior alternância entre threads. Deixar
	uma thread executar enquanto sua prioridade é maior que
	as threads em espera seria uma outra forma de abordar o
	escalonamento.


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

Para ter um controle melhor dos bits de cada número na aritmética de
Fixed Point. Os macros (#define) e datatypes abstratos (typedef) foram
utilizados para possibilitar maior abstração das tais funções na porção
de código em que elas são chamadas.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
